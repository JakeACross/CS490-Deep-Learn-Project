{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6baefff",
   "metadata": {},
   "source": [
    "# Facial Recognition: Transfer Learning Video Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b933b0",
   "metadata": {},
   "source": [
    "### Libraries Used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd43df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used for OpenCv and path creation/reading\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "# Keras libraries necessary for the model creation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "\n",
    "# Keras library for VGG16 model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# Libraries for preprocessing the data\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array, save_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from glob import glob\n",
    "\n",
    "# Importing numpy to work with arrays, matplotlib for visuals\n",
    "# and pandas for dataframe.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import spatial\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac38538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds the cosine similarity between the dataset image\n",
    "# and the captured images\n",
    "def cosineSimilarity(dataset_img, captured_img):\n",
    "    cos_dis = spatial.distance.cosine(dataset_img, captured_img)\n",
    "    cos_sim = 1 - cos_dis\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce970ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FR TL model\n",
    "tl_model = load_model('fr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc75511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jacob Paszkiewicz', 'Jake Cross', 'Txomin Chivite']\n"
     ]
    }
   ],
   "source": [
    "user_names = []\n",
    "name = r'C:\\Users\\jpasz\\Facial Recognition TVT\\train'\n",
    "# print(os.listdir(name))\n",
    "# This list comprehension stores all of the user names into a list.\n",
    "user_names = [i for i in os.listdir(name)]\n",
    "print(user_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f823148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/jpasz/Facial Recognition Images/Jacob Paszkiewicz\n",
      "Found 150 images belonging to 1 classes.\n",
      "Jacob Paszkiewicz\n",
      "C:/Users/jpasz/Facial Recognition Images/Jake Cross\n",
      "Found 108 images belonging to 1 classes.\n",
      "Jake Cross\n",
      "C:/Users/jpasz/Facial Recognition Images/Txomin Chivite\n",
      "Found 150 images belonging to 1 classes.\n",
      "Txomin Chivite\n"
     ]
    }
   ],
   "source": [
    "# Initialize a file name and dictionary\n",
    "user_image_path = r'C:/Users/jpasz/Facial Recognition Images'\n",
    "user_images = dict()\n",
    "# Iterate a folder (\"New Faces\") to folder (\"User name\") to user's 150 face images\n",
    "# String beocomes file path by listdir\n",
    "for i in listdir(user_image_path):\n",
    "    if i != '.DS_Store':  # for mac users\n",
    "        current_folder = user_image_path + '/' + i\n",
    "        print(current_folder)\n",
    "        # initialize and reset a list\n",
    "        image_predictions = []\n",
    "        # Creates the test data with imagedatagenerator\n",
    "        temp_i = ImageDataGenerator(rescale=1.0/255.0)\n",
    "        i_data = temp_i.flow_from_directory(user_image_path, classes=[i], target_size=(224, 224),\n",
    "                                             batch_size=16, class_mode='categorical')\n",
    "        i_img, i_labels = next(i_data) # load images inside of imagedatagenerator\n",
    "        pred = tl_model.predict(i_img) # get values from each images by model.predict\n",
    "        # print(pred)\n",
    "        # print(pred[0])\n",
    "        print(user_names[pred[0].argmax()])\n",
    "        user_images[i] = pred # assign the list to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3ce28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7477066  0.25229335 0.         0.        ]\n",
      "Unrecognized User\n",
      "[1.000000e+00 8.551457e-25 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 3.5974733e-22 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.2309135e-13 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.1089385e-11 0.0000000e+00 0.0000000e+00]\n",
      "[9.9985003e-01 1.4996219e-04 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.2795548e-10 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.6465724e-10 0.0000000e+00 0.0000000e+00]\n",
      "[9.9999702e-01 2.9484102e-06 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.0774679e-11 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.9405663e-21 0.0000000e+00 0.0000000e+00]\n",
      "[1.000000e+00 8.173524e-12 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 3.7584196e-13 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.4794133e-26 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 3.5346623e-10 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.6892413e-17 0.0000000e+00 0.0000000e+00]\n",
      "[1.000000e+00 4.679924e-22 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 1.2138869e-17 0.0000000e+00 0.0000000e+00]\n",
      "[9.9998379e-01 1.6195241e-05 0.0000000e+00 0.0000000e+00]\n",
      "[5.9856240e-05 1.5418957e-20 9.9994016e-01 6.9907719e-26]\n",
      "[1.0000000e+00 2.8474632e-23 0.0000000e+00 0.0000000e+00]\n",
      "[9.9999976e-01 2.0061100e-07 0.0000000e+00 0.0000000e+00]\n",
      "[2.1575822e-03 4.3805490e-11 9.9784243e-01 8.5136450e-21]\n",
      "[1.000000e+00 4.764762e-10 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 1.7348256e-08 3.7110248e-26 5.6673384e-35]\n",
      "[2.2590293e-12 1.0000000e+00 2.7511205e-12 9.5370667e-34]\n",
      "[9.7853869e-01 2.1461302e-02 1.4418259e-12 1.0419759e-28]\n",
      "[9.9999893e-01 2.7080913e-10 1.0173140e-06 2.7428822e-30]\n",
      "[1.0000000e+00 2.3335377e-15 9.3561979e-21 1.5707403e-35]\n",
      "[9.9999952e-01 5.1853908e-07 1.4357009e-20 4.8100416e-36]\n",
      "[7.2589592e-07 2.7875224e-23 9.9999928e-01 3.2544062e-25]\n",
      "[1.5369753e-09 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "[5.4209137e-10 1.0000000e+00 3.3334503e-34 0.0000000e+00]\n",
      "[1.0000000e+00 5.3970254e-08 2.3110223e-27 0.0000000e+00]\n",
      "[1.000000e+00 5.385213e-26 6.145331e-23 0.000000e+00]\n",
      "[1.000000e+00 8.803761e-14 8.108748e-33 0.000000e+00]\n",
      "[1.0000000e+00 3.1502018e-19 3.6944554e-19 0.0000000e+00]\n",
      "[1.0000000e+00 1.3134528e-11 5.4804732e-29 0.0000000e+00]\n",
      "[2.3209354e-19 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 9.5876390e-16 5.4345417e-31 0.0000000e+00]\n",
      "[1.5851857e-02 7.7188468e-01 2.1226344e-01 3.2322632e-29]\n",
      "[1.0000000e+00 9.6695714e-11 0.0000000e+00 0.0000000e+00]\n",
      "[1.000000e+00 1.537132e-11 0.000000e+00 0.000000e+00]\n",
      "[3.1194463e-03 9.9688053e-01 2.3496286e-34 0.0000000e+00]\n",
      "[1.000000e+00 1.930603e-09 0.000000e+00 0.000000e+00]\n",
      "[1.3308379e-07 9.9999988e-01 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.8547205e-13 0.0000000e+00 0.0000000e+00]\n",
      "[3.9678912e-07 9.9999964e-01 0.0000000e+00 0.0000000e+00]\n",
      "[9.6453810e-01 3.5461910e-02 5.3298105e-14 1.5934851e-30]\n",
      "[7.6410537e-14 6.3883968e-25 1.0000000e+00 2.0638349e-33]\n",
      "[1.0000000e+00 4.2752276e-18 1.8753744e-35 0.0000000e+00]\n",
      "[1.000000e+00 8.857373e-10 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 3.4616548e-08 1.6551686e-29 1.1782074e-37]\n",
      "[2.2637827e-05 9.9997735e-01 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.9815727e-08 1.6656434e-31 1.5656947e-38]\n",
      "[9.9998176e-01 1.8212928e-05 9.6906475e-37 0.0000000e+00]\n",
      "[4.0754062e-01 5.9245938e-01 1.7432073e-32 0.0000000e+00]\n",
      "Unrecognized User\n",
      "[7.05372589e-03 9.92946327e-01 1.00978276e-25 0.00000000e+00]\n",
      "[1.0000000e+00 1.0684397e-13 9.3826337e-16 1.8389649e-31]\n",
      "[1.000000e+00 2.736132e-09 0.000000e+00 0.000000e+00]\n",
      "[1.0000000e+00 5.6723605e-11 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.7527045e-09 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 3.2335378e-14 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 6.3589605e-15 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 2.7679523e-16 0.0000000e+00 0.0000000e+00]\n",
      "[1.000000e+00 5.030283e-12 0.000000e+00 0.000000e+00]\n",
      "[9.9999928e-01 7.3175806e-07 0.0000000e+00 0.0000000e+00]\n",
      "[1.0000000e+00 1.5348345e-12 0.0000000e+00 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# The webcamera is opened up with OpenCV.\n",
    "camera = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    result, image = camera.read() # get a image from webcam capture\n",
    "    # If the image capture is sucessful, this if statement is run\n",
    "    if result:\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "        detected_faces = face_cascade.detectMultiScale(image, 1.1, 4) # Find faces in the captured image\n",
    "        for (x, y, w, h) in detected_faces: # x, y represents initial posions in a graph. w is width and h is height\n",
    "            user_detected = False\n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            face_recognized = image[y:y + h, x:x + w] # crop detected face\n",
    "            face_recognized = cv2.resize(face_recognized, dsize=(224, 224)) # resize to 224x224\n",
    "            face_array = img_to_array(face_recognized)\n",
    "            face_expanded = np.expand_dims(face_array, axis=0)\n",
    "            face_preprocessed = preprocess_input(face_expanded)\n",
    "            # Assign the image extracted from the webcam\n",
    "            video_prediction = tl_model.predict(face_preprocessed)\n",
    "            print(video_prediction[0])\n",
    "            # i is a key of dict which is user's name\n",
    "            for i in user_images:\n",
    "                user_folder = user_images[i]\n",
    "                for j in user_folder:\n",
    "                    cosine_similarity = cosineSimilarity(j, video_prediction[0])\n",
    "                    # If cosine similarity is greater than 0.95, then consider that detected\n",
    "                    # face as the user in folder k, and increment the counter.\n",
    "                    if(cosine_similarity >= 0.95):\n",
    "                        # print(cosine_similarity)\n",
    "                        cv2.putText(image, user_names[video_prediction[0].argmax()],\n",
    "                                    (int(x+w+20), int(y-15)), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0, 0), 1)\n",
    "                        user_detected=True\n",
    "                        break\n",
    "             # If the detected image is not in user's face dataset, then display unauthorized\n",
    "            if(user_detected==False):\n",
    "                cv2.putText(image, 'Unrecogized User', (int(x+w+20), int(y-15)), cv2.FONT_HERSHEY_TRIPLEX, 1, (0, 0, 0), 1)\n",
    "                print('Unrecognized User')\n",
    "    # Displays the webcamera to the user.\n",
    "    cv2.imshow('Facial Recognition', image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break\n",
    "# These two lines shut down OpenCV\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()           \n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba859aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd5894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tensorflow",
   "language": "python",
   "name": "gpu_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
