{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98e0625a",
   "metadata": {},
   "source": [
    "### Reference \n",
    "Code: https://github.com/serengil/tensorflow-101/blob/master/python/deep-face-real-time.py   \n",
    "Description: https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49625960",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0032b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf713647",
   "metadata": {},
   "source": [
    "RGB color code for texts. 0, 255, 0 is lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbaf80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = (0,255,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d75b60",
   "metadata": {},
   "source": [
    "Create a classifier for face detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ed967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f14936",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64b1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess_input normalizes input in scale of [-1, +1]. You must apply same normalization in prediction.\n",
    "# Devide the array by 127.5 and substract by 1\n",
    "# Ref: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py (Line 45)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    img = img_to_array(image)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a490e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a cosine distance between two values. Distance between similar vectors should be low.\n",
    "\n",
    "def findCosineDistance(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ae529c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN \n",
    "# Download data from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "\n",
    "def loadVggFaceModel():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Load pretrained weights for VGGFace\n",
    "    from keras.models import model_from_json\n",
    "    model.load_weights('/Users/jake/Desktop/CS490/Project/vgg_face_weights.h5')\n",
    "    \n",
    "    # Generate model with input and output\n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "    return vgg_face_descriptor  # return the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81945619",
   "metadata": {},
   "source": [
    "### Real time face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e724795",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 10:31:28.775658: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d_input (Input  [(None, 224, 224, 3)]    0         \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " zero_padding2d (ZeroPadding  (None, 226, 226, 3)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPaddi  (None, 226, 226, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPaddi  (None, 114, 114, 64)     0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " zero_padding2d_3 (ZeroPaddi  (None, 114, 114, 128)    0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_4 (ZeroPaddi  (None, 58, 58, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " zero_padding2d_5 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " zero_padding2d_6 (ZeroPaddi  (None, 58, 58, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_7 (ZeroPaddi  (None, 30, 30, 256)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " zero_padding2d_8 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_9 (ZeroPaddi  (None, 30, 30, 512)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_10 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_11 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " zero_padding2d_12 (ZeroPadd  (None, 16, 16, 512)      0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 1, 1, 4096)        102764544 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 1, 4096)        0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 1, 1, 4096)        16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 1, 4096)        0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 1, 1, 2622)        10742334  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2622)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Generate a model by function call\n",
    "model = loadVggFaceModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5155b764",
   "metadata": {},
   "source": [
    "Use the cnn model and assign new images captured by OpenCV FR Dataset Generation.ipynb. We can say the images are train datasets.\n",
    "The output from the cnn is saved in dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1294aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a file name and dictionary\n",
    "new_pictures_folder = \"New Faces\"\n",
    "new_pictures = dict()\n",
    "\n",
    "# Iterate a folder (\"New Faces\") to folder (\"User name\") to user's 150 face images\n",
    "# String beocomes file path by listdir\n",
    "for folder_name in listdir(new_pictures_folder):\n",
    "    if folder_name != '.DS_Store':  # for mac users\n",
    "        \n",
    "        folder_path = new_pictures_folder+'/'+folder_name  # create a path for the next folder to iterate\n",
    "        \n",
    "        pred = []  # initialize and reset a list\n",
    "        \n",
    "        for file_name in listdir(folder_path):\n",
    "            file_name = folder_path+'/'+file_name  # create a path for the files\n",
    "            face_img = load_img(file_name, target_size=(224, 224))  # load images by the path\n",
    "            pred.append(model.predict(preprocess_image(face_img))[0,:])  # get values from each images by model.predict\n",
    "            \n",
    "        new_pictures[folder_name] = pred  # assign the list to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664bcc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.685139  -0.9130396  0.7525303 ... -1.280415  -0.6542321  0.7728258]\n",
      "2622\n",
      "Unknown\n",
      "Unknown\n",
      "Unknown\n"
     ]
    }
   ],
   "source": [
    "img = load_img(\"jackman.png\", target_size=(224, 224))\n",
    "img = preprocess_image(img)\n",
    "value= model.predict(img)[0,:]\n",
    "print(value)\n",
    "print(len(value))\n",
    "\n",
    "found = 0 \n",
    "\n",
    "for k in new_pictures:  # k is a key of dict which is user's name\n",
    "    folder = new_pictures[k]\n",
    "    for i in folder:\n",
    "        distance = findCosineDistance(i, value)\n",
    "                    \n",
    "        # If cosine distance is small, consider it is k (user's name)\n",
    "        if(distance < 0.30): \n",
    "            print(k)\n",
    "            found = 1\n",
    "            break\n",
    "        # if found image is not in user's face dataset, display unknown\n",
    "    if(found == 0): \n",
    "        print('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e57d1",
   "metadata": {},
   "source": [
    "The saved values in the dictionary is compared with images (we can say test datasets) extracted from a real time video.   \n",
    "If a cosine distance between values in the dictionary and the values from webcam images is very small, it is considered as the same face and displays the user's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba014e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_cascade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b4/r9wc37x16cz4gn0qqlskcfth0000gn/T/ipykernel_2719/2404158208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get a image from webcam capture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# find faces in images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# x, y represents initial posions in a graph. w is width and h is height\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'face_cascade' is not defined"
     ]
    }
   ],
   "source": [
    "# Open webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, img = cap.read()  # get a image from webcam capture\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)  # find faces in images\n",
    "\n",
    "    for (x,y,w,h) in faces:  # x, y represents initial posions in a graph. w is width and h is height\n",
    "        if w > 130: \n",
    "\n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] # crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) # resize to 224x224\n",
    "\n",
    "            img_pixels = preprocess_image(detected_face)\n",
    "            \n",
    "            # Assign the image extracted from webcam\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0  # counter\n",
    "            \n",
    "            for k in new_pictures:  # k is a key of dict which is user's name\n",
    "                folder = new_pictures[k]\n",
    "                for i in folder:\n",
    "                    distance = findCosineDistance(i, captured_representation)\n",
    "                    \n",
    "                    # If cosine distance is small, consider it is k (user's name)\n",
    "                    if(distance < 0.30): \n",
    "                        cv2.putText(img, k, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                    \n",
    "                        found = 1\n",
    "                        break\n",
    "\n",
    "            # Connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),color,1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),color,1)\n",
    "            \n",
    "            # if found image is not in user's face dataset, display unknown\n",
    "            if(found == 0): \n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # press q to quit\n",
    "        break\n",
    "\n",
    "# Kill open cv things\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs490_python_projects",
   "language": "python",
   "name": "cs490_python_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
