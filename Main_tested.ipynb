{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b1af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "color = (67,67,67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d560b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') #path to this file\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    #preprocess_input normalizes input in scale of [-1, +1]. You must apply same normalization in prediction.\n",
    "    #Ref: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py (Line 45)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6996c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVggFaceModel():\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(2622, (1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # you can download pretrained weights from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "    from keras.models import model_from_json\n",
    "    model.load_weights('vgg_face_weights.h5')\n",
    "    \n",
    "    vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
    "\n",
    "    return vgg_face_descriptor\n",
    "model = loadVggFaceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfc0d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employee representations retrieved successfully\n"
     ]
    }
   ],
   "source": [
    "new_pictures_folder = \"New Faces\"\n",
    "\n",
    "users = dict()\n",
    "\n",
    "for file in listdir(new_pictures_folder):\n",
    "    employee, extension = file.split(\".\")\n",
    "    users[employee] = model.predict(preprocess_image('New Faces/%s.jpg' % (employee)))[0,:]\n",
    "    \n",
    "print(\"employee representations retrieved successfully\")\n",
    "\n",
    "def findCosineSimilarity(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b13aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n",
      "USER CAPTURED IS : 1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0) #webcam\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    #img = cv2.resize(img, (640, 360))\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        if w > 130: \n",
    "            detected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "            detected_face = cv2.resize(detected_face, (224, 224)) #resize to 224x224\n",
    "\n",
    "            img_pixels = image.img_to_array(detected_face)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            #employee dictionary is using preprocess_image and it normalizes in scale of [-1, +1]\n",
    "            img_pixels /= 127.5\n",
    "            img_pixels -= 1\n",
    "\n",
    "            captured_representation = model.predict(img_pixels)[0,:]\n",
    "\n",
    "            found = 0\n",
    "            for i in users:\n",
    "                employee_name = i\n",
    "                representation = users[i]\n",
    "\n",
    "                similarity = findCosineSimilarity(representation, captured_representation)\n",
    "                if(similarity < 0.30):\n",
    "                    cv2.putText(img, employee_name, (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "                    \n",
    "                    found = 1\n",
    "                    print('USER CAPTURED IS :',employee_name)\n",
    "                    break\n",
    "\n",
    "            #connect face and text\n",
    "            cv2.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),color,1)\n",
    "            cv2.line(img,(x+w,y-20),(x+w+10,y-20),color,1)\n",
    "\n",
    "            if(found == 0): #if found image is not in employee database\n",
    "                cv2.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "        break\n",
    "\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc427514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
